{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marqo\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from index_settings import pmec_index_settings\n",
    "\n",
    "mq = marqo.Client(url='http://localhost:8882')\n",
    "index_name = \"wny-manufacturing-companies\"\n",
    "local_json_filename = 'sample.json'\n",
    "\n",
    "def read_json_documents(mode='single', preprocess=True, folder_prefix='data'):\n",
    "    \"\"\"\"\n",
    "    Read JSON objects (either a single consolidated file or multiple individual files) \n",
    "    in the specified folder and return their content as a list of objects.\n",
    "\n",
    "    :param: mode: Either 'single' or 'multi'. In 'single' mode, it is assumed that all\n",
    "            data is in a single consolidated JSON file (list of objects). In 'multi'\n",
    "            mode, all JSON files in the specified directory are ingested.\n",
    "    :param: preprocess: Toggle preprocessing (str-concatenating lists, etc)\n",
    "    :param: folder_prefix: A folder path relative from the working directory which contains\n",
    "            JSON data. By default, it assumes the folder is called 'data'.\n",
    "    \"\"\"\n",
    "    document_list = []\n",
    "    print(f'Document fetch mode: {mode}. Preprocessing: {preprocess}')\n",
    "    if mode == 'single':\n",
    "        with open(os.path.join(folder_prefix, os.listdir(folder_prefix)[0]), 'r') as f:\n",
    "            print(f\"Using consolidated file: '{os.path.join(folder_prefix, os.listdir(folder_prefix)[0])}'\")\n",
    "            json_data = json.load(f)\n",
    "            for json_object in json_data:\n",
    "                if preprocess:\n",
    "                    json_data = flatten_json(json_object=json_object)\n",
    "                else:\n",
    "                    json_data=json_object\n",
    "                document_list.append(json_data)\n",
    "    elif mode == 'multiple':\n",
    "        print(f\"Found {len(os.listdir())} objects under {folder_prefix}/.\")\n",
    "        for filename in os.listdir(folder_prefix):\n",
    "            with open(os.path.join(folder_prefix, filename), 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "                if preprocess:\n",
    "                    json_data = flatten_json(json_object=json_object)\n",
    "                else:\n",
    "                    json_data=json_object\n",
    "                document_list.append(json_data)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid mode: '{mode}' \")\n",
    "    print(f\"{len(document_list)} object(s) extracted.\")\n",
    "    return document_list\n",
    "\n",
    "def flatten_json(json_object):\n",
    "    \"\"\"Flatten composite structured in a JSON object and return it.\"\"\"\n",
    "    for key, value in json_object.items():\n",
    "        if type(value) is list:\n",
    "            json_object[key] = ', '.join(value)\n",
    "    return json_object\n",
    "\n",
    "def clear_indexes_if_exist(index_name=index_name):\n",
    "    # Drop existing index - for development purposes\n",
    "    for index in mq.get_indexes()['results']:\n",
    "        if index['indexName'] == index_name:\n",
    "            mq.index(index_name=index['indexName']).delete()\n",
    "            print(f\"Index '{index_name}' cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'wny-manufacturing-companies' cleared.\n",
      "{'allFields': [{'features': ['lexical_search', 'filter'],\n",
      "                'name': 'company_id',\n",
      "                'type': 'text'},\n",
      "               {'features': ['lexical_search'],\n",
      "                'name': 'company_name',\n",
      "                'type': 'text'},\n",
      "               {'features': ['lexical_search'],\n",
      "                'name': 'datapoint_type',\n",
      "                'type': 'text'},\n",
      "               {'features': ['lexical_search'],\n",
      "                'name': 'datapoint_value',\n",
      "                'type': 'text'},\n",
      "               {'features': ['lexical_search'],\n",
      "                'name': 'source_urls',\n",
      "                'type': 'array<text>'},\n",
      "               {'features': ['lexical_search'],\n",
      "                'name': 'source_inferred',\n",
      "                'type': 'array<text>'},\n",
      "               {'features': ['lexical_search'],\n",
      "                'name': 'source_excerpts',\n",
      "                'type': 'array<text>'}],\n",
      " 'tensorFields': ['company_name', 'datapoint_value', 'datapoint_type'],\n",
      " 'type': 'structured'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'index': 'wny-manufacturing-companies'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop and recreate index\n",
    "clear_indexes_if_exist()\n",
    "pprint(pmec_index_settings)\n",
    "mq.create_index(index_name, settings_dict=pmec_index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document fetch mode: single. Preprocessing: False\n",
      "Using consolidated file: 'data/sample.json'\n",
      "7 object(s) extracted.\n",
      "{'errors': False, 'processingTimeMs': 1089.7209590002603, 'index_name': 'wny-manufacturing-companies', 'items': [{'status': 200, '_id': 'b3ce19ed-9baa-4ea3-8f05-555ab64f0fd4'}, {'status': 200, '_id': '8361b4e3-6cad-4138-a52f-fd46f9249e60'}, {'status': 200, '_id': '8a0171a3-ad18-45f2-a0bc-23f59f03490b'}, {'status': 200, '_id': 'c36153e5-812a-48cd-b0a0-928af0b11a5b'}, {'status': 200, '_id': '1046612d-2e14-46b1-a1e6-fce9817b7f52'}, {'status': 200, '_id': '2c09dd7c-714e-414f-9a50-44c70ddaac0f'}, {'status': 200, '_id': 'eca16d1d-cbfa-46e9-aee8-d880d3af00ad'}]}\n"
     ]
    }
   ],
   "source": [
    "# Add JSON data\n",
    "json_documents = read_json_documents(mode='single', preprocess=False)\n",
    "result = mq.index(index_name).add_documents(json_documents)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_load_model_from_file: using device Metal (Apple M3 Pro) - 12282 MiB free\n",
      "llama_model_loader: loaded meta data with 33 key-value pairs and 292 tensors from models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Meta-Llama-3.1\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 8B\n",
      "llama_model_loader: - kv   6:                            general.license str              = llama3.1\n",
      "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   9:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  17:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  28:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  29:                      quantize.imatrix.file str              = /models_out/Meta-Llama-3.1-8B-Instruc...\n",
      "llama_model_loader: - kv  30:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  31:             quantize.imatrix.entries_count i32              = 224\n",
      "llama_model_loader: - kv  32:              quantize.imatrix.chunks_count i32              = 125\n",
      "llama_model_loader: - type  f32:   66 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.7999 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
      "llm_load_print_meta: general.name     = Meta Llama 3.1 8B Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q4_K) (and 322 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =  4685.30 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 1024\n",
      "llama_new_context_with_model: n_ctx_per_seq = 1024\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 500000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (1024) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M3 Pro\n",
      "ggml_metal_init: picking default device: Apple M3 Pro\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M3 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 12884.92 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x15ca1eb60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                                0x15ca441e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x12f6caee0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row                                0x15c90b450 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x15cfa3760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                                0x12ba40d10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x12ba41730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row                                0x12ba3f220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x12ba3f780 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x15c90bc50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x15cfa4310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x12ba424c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x12ba42a90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x12ba433c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x12ba43bd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x12ba449f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x12ba454b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x10c5b1420 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x10c55a0d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x15c90a400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x15cfa3c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x15cfa4ce0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x10c5b4710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x10c5b4d80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x10c5b52c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x15c90c2c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x15c90cd20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x10c5b58a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x10c5b6150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x10c5b6700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x10c5b6d40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x15cfa5c10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x10c5b7320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x10c5b7ab0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x15c90e500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x10c5b83e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x15c90e9e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x15cfa5290 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x15cfa6ee0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x15cfa7780 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x10c5b7660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x15c90ede0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x15c90d650 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x15cfa80d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x15cfa8e60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x15cfa98b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x12ba45840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x15cfaa030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x12ba44fe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x15cc0c150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x15c90fa00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x12ba45e60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x12ba46500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x10c5b9040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x15ca444a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x15ca44760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x15ca44d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x10c5b9ae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x10c5b9da0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x15c9106b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x15cfaa5a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x15cfab390 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x15c911790 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x15c911fb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x15cfabc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x15c912820 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x15c913070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x15cfac410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x10c5babb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x15c9138e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x15c914200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x15c914920 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x15c915000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x15c915790 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x10c5ba710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x15c915a50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x15c9163c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x15c916ce0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x12ba46d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x15cc0d150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x15cc0e350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x15cc0ec40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x15cfad320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x10c5bb9f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x15ca451c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x15ca45550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x15ca45e50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x15ca465e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x12ba47880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x12ba47f30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x12ba48ab0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x12ba493d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x15c915d10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x15c9175c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x12ba49b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x10c5bc340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x12ba49dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x12ba4adc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x12ba4b6c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x15c918a70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x15c9180b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x15c919c50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x15c919280 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x15c91ae20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x15c91a410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x12ba4a6c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x15cfadfa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x15ca468a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x10c5bd590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x15ca47230 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x15cfae580 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x15cfaf3a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x15cfafc30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x15cfb0450 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x15c91b5d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x15c91c520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x12ba4c840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x10c5be3d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x10c5bec90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x12ba4c1b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x12ba4d6a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x10c5bf890 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x10c5c0180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x10c5c0a80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x12ba4dfd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x15ca47ab0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x10c5c1350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x15c91ce30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x15c91d750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x15cc0f530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x15ca46b60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x15c91be40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x15cc0fc90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x10c5c2000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x15c91e8d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x15c91f1f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x12ba4e8f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x15c91fa90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x15c9203b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x15cfb0bd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x15c920b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x15c921200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x10c5c2880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x10c5c3190 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x10c5c3560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x15c921b30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x15cfaedc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x15c922350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x15c922bb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x15cfb2180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x15cfb29b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x12ba4f1c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x15cfb3210 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x10c5c5650 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x15c9233a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x15c923bf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x15ca48900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x10c5e8110 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x15cfb3a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x10c5c3f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x15c9244b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x15c924dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x15ca48240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x15ca497a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f32                      0x15ca4a0d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f32                      0x15ca4aa30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f32                     0x15cc0ff50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f32                     0x15ca4b310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f32                     0x12cf15fa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f32                     0x12ba4cfc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f32                     0x14bfab250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f32                     0x15c808f90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f32                     0x12ce045e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f32                     0x14bfab510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f32                     0x15c809250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f32                     0x15cfb1950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f32                  0x12ce05440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f32                   0x14bfab7d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f32                  0x15c80a0f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f32                    0x12f7040b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f32                    0x12ce058e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f32                    0x12ba4f990 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f32                    0x14bfaba90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f32                   0x12ce06010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f32                   0x15c9254e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x12ba4fe00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x15cfb0fe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x15ca4bd60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x15c926190 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x15c925c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x12ba50230 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x10c5c4cd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x15c927250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x10c5e9940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x15cc10210 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x15c926960 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x15ca4c020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x10c5e9f30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x10c5eac70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x15c9284d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x10c5ea340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x12cf16260 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x14bfac060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x12f7049d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x12ce062d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x12ce07140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x15c929190 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x15c928b10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x10c5eb9e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x15cfb5aa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x10c5ebca0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x10c5ecfa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x15c929c20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x15cfb5f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x10c5edbb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x10c5ec5d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x15c92a4a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x10c5ee920 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x15ca4ccb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x15cfb6fc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x12ba51790 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x15cfb7bd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x15c92a760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x12ba50ff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x15ca4d3d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x15ca4e1a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x15ca4eab0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x15ca4f3b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x10c5ef860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x15cfb87f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x12ba52a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x10c5efd40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x15c92b060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x15c92c010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x12ba52ec0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x12ba51fe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x12ba54400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x15c92baf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x15cfb47e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x15cfb9170 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x15c92d580 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x10c5f0090 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x15cfb9ad0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x15cfba410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x15cfbad00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x10c5f1310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x10c5f05d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x15cfbbaa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x15cfb8c60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x12ba54d30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x15ca4f820 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x15ca4db30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x10c5f20e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x15c92d9e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x15c92b520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x10c5f24b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x12ba54790 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x12ba56240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x12ba53500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x15c92e0c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x15cfbc760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x10c5ef2f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x15cfbcf80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x10c5f2da0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x15c92e9e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x15cfbd3f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x10c5f3d80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x15cfbddf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x15cfbe3d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x15cfbe850 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x15ca50450 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x15ca507a0 | th_max = 1024 | th_width =   32\n",
      "llama_kv_cache_init:        CPU KV buffer size =   128.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  128.00 MiB, K (f16):   64.00 MiB, V (f16):   64.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   258.50 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 514 (with bs=512), 1 (with bs=1)\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'quantize.imatrix.file': '/models_out/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct.imatrix', 'quantize.imatrix.chunks_count': '125', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- set date_string = \"26 Jul 2024\" %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message + builtin tools #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if builtin_tools is defined or tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{%- if builtin_tools is defined %}\\n    {{- \"Tools: \" + builtin_tools | reject(\\'equalto\\', \\'code_interpreter\\') | join(\", \") + \"\\\\n\\\\n\"}}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\\n            {%- for arg_name, arg_val in tool_call.arguments | items %}\\n                {{- arg_name + \\'=\"\\' + arg_val + \\'\"\\' }}\\n                {%- if not loop.last %}\\n                    {{- \", \" }}\\n                {%- endif %}\\n                {%- endfor %}\\n            {{- \")\" }}\\n        {%- else  %}\\n            {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n            {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n            {{- \\'\"parameters\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \"}\" }}\\n        {%- endif %}\\n        {%- if builtin_tools is defined %}\\n            {#- This means we\\'re in ipython mode #}\\n            {{- \"<|eom_id|>\" }}\\n        {%- else %}\\n            {{- \"<|eot_id|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.type': 'model', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.pre': 'llama-bpe', 'tokenizer.ggml.model': 'gpt2', 'llama.embedding_length': '4096', 'llama.vocab_size': '128256', 'llama.attention.head_count_kv': '8', 'general.finetune': 'Instruct', 'general.file_type': '15', 'llama.block_count': '32', 'general.size_label': '8B', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.feed_forward_length': '14336', 'general.quantization_version': '2', 'llama.rope.dimension_count': '128', 'general.license': 'llama3.1', 'llama.attention.head_count': '32', 'quantize.imatrix.entries_count': '224', 'llama.context_length': '131072', 'general.architecture': 'llama', 'general.basename': 'Meta-Llama-3.1', 'llama.rope.freq_base': '500000.000000', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'general.name': 'Meta Llama 3.1 8B Instruct'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- set date_string = \"26 Jul 2024\" %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message + builtin tools #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if builtin_tools is defined or tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{%- if builtin_tools is defined %}\n",
      "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
      "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
      "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
      "                {%- if not loop.last %}\n",
      "                    {{- \", \" }}\n",
      "                {%- endif %}\n",
      "                {%- endfor %}\n",
      "            {{- \")\" }}\n",
      "        {%- else  %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "            {{- '\"parameters\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- \"}\" }}\n",
      "        {%- endif %}\n",
      "        {%- if builtin_tools is defined %}\n",
      "            {#- This means we're in ipython mode #}\n",
      "            {{- \"<|eom_id|>\" }}\n",
      "        {%- else %}\n",
      "            {{- \"<|eot_id|>\" }}\n",
      "        {%- endif %}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "LLM = Llama(\n",
    "    model_path=\"models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\",\n",
    "    n_ctx=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The query was: What companies are located in Buffalo that service gas pipes and lines?\n",
      "\n",
      "Hits from Vector DB: \n",
      "==============\n",
      "\n",
      "ID: 1046612d-2e14-46b1-a1e6-fce9817b7f52, Score: 0.841.\n",
      "Company Name: Pii Holdings, Inc.\n",
      "Relevant data:\n",
      "[{'datapoint_value': 'gas pipe fixtures'}]\n",
      "{'hits': [{'_highlights': [{'datapoint_value': 'gas pipe fixtures'}],\n",
      "           '_id': '1046612d-2e14-46b1-a1e6-fce9817b7f52',\n",
      "           '_score': 0.8411167170910742,\n",
      "           'company_id': '999',\n",
      "           'company_name': 'Pii Holdings, Inc.',\n",
      "           'datapoint_type': 'product',\n",
      "           'datapoint_value': 'gas pipe fixtures',\n",
      "           'source_excerpts': ['we do gas pipes on a daily basis.'],\n",
      "           'source_inferred': ['we do gas pipes on a daily basis.'],\n",
      "           'source_urls': ['https://www.growertalks.com/Article/?articleid=21683']},\n",
      "          {'_highlights': [{'datapoint_value': '3288 Main St. Buffalo NY'}],\n",
      "           '_id': '2c09dd7c-714e-414f-9a50-44c70ddaac0f',\n",
      "           '_score': 0.8306013006661755,\n",
      "           'company_id': '1010',\n",
      "           'company_name': 'XYZ Inc.',\n",
      "           'datapoint_type': 'location',\n",
      "           'datapoint_value': '3288 Main St. Buffalo NY',\n",
      "           'source_excerpts': ['visit our website.'],\n",
      "           'source_inferred': ['.'],\n",
      "           'source_urls': ['https://www.growertalks.com/Article/?articleid=21683']},\n",
      "          {'_highlights': [{'datapoint_value': '2150 Elmwood Avenue Buffalo, '\n",
      "                                               'NY'}],\n",
      "           '_id': '98ce1371-890d-47ee-bd66-a79043a50d05',\n",
      "           '_score': 0.8284792098690519,\n",
      "           'company_id': '999',\n",
      "           'company_name': 'Pii Holdings, Inc.',\n",
      "           'datapoint_type': 'location',\n",
      "           'datapoint_value': '2150 Elmwood Avenue Buffalo, NY',\n",
      "           'source_excerpts': ['they also have a division that designs and '\n",
      "                               'installs racks for solar panels.'],\n",
      "           'source_inferred': ['Solar panel racking systems are part of '\n",
      "                               \"Rough's offerings as they have a division that \"\n",
      "                               'designs and installs racks for solar panels.'],\n",
      "           'source_urls': ['https://www.growertalks.com/Article/?articleid=21683']},\n",
      "          {'_highlights': [{'datapoint_value': '2150 Elmwood Avenue Buffalo, '\n",
      "                                               'NY'}],\n",
      "           '_id': 'c36153e5-812a-48cd-b0a0-928af0b11a5b',\n",
      "           '_score': 0.8284792098690519,\n",
      "           'company_id': '999',\n",
      "           'company_name': 'Pii Holdings, Inc.',\n",
      "           'datapoint_type': 'location',\n",
      "           'datapoint_value': '2150 Elmwood Avenue Buffalo, NY',\n",
      "           'source_excerpts': ['they also have a division that designs and '\n",
      "                               'installs racks for solar panels.'],\n",
      "           'source_inferred': ['Solar panel racking systems are part of '\n",
      "                               \"Rough's offerings as they have a division that \"\n",
      "                               'designs and installs racks for solar panels.'],\n",
      "           'source_urls': ['https://www.growertalks.com/Article/?articleid=21683']},\n",
      "          {'_highlights': [{'company_name': 'XYZ Inc.'}],\n",
      "           '_id': 'eca16d1d-cbfa-46e9-aee8-d880d3af00ad',\n",
      "           '_score': 0.7882498025759656,\n",
      "           'company_id': '1010',\n",
      "           'company_name': 'XYZ Inc.',\n",
      "           'datapoint_type': 'product',\n",
      "           'datapoint_value': '3D printing',\n",
      "           'source_excerpts': ['our latest resin printers and sintering '\n",
      "                               'machines.'],\n",
      "           'source_inferred': ['.'],\n",
      "           'source_urls': ['https://www.growertalks.com/Article/?articleid=21683']},\n",
      "          {'_highlights': [{'datapoint_value': 'greenhouses'}],\n",
      "           '_id': 'e14baf37-a771-47aa-aaaf-aedcafa206b6',\n",
      "           '_score': 0.7853126840150648,\n",
      "           'company_id': '123',\n",
      "           'company_name': 'Rough Brothers Holding Co., Inc',\n",
      "           'datapoint_type': 'product',\n",
      "           'datapoint_value': 'greenhouses',\n",
      "           'source_excerpts': ['Rough (rhymes with now) doesnt just design and '\n",
      "                               'build greenhouses (commercial, retail and '\n",
      "                               'institutional)...',\n",
      "                               'St. Bernard-based Rough Brothers was founded '\n",
      "                               'in 1932 and is among North Americas largest '\n",
      "                               'greenhouse manufacturers.'],\n",
      "           'source_inferred': ['null', 'null'],\n",
      "           'source_urls': ['https://www.growertalks.com/Article/?articleid=21683',\n",
      "                           'https://www.cincinnati.com/story/money/2015/07/08/rough-brothers-rbi-sold/29870299/']},\n",
      "          {'_highlights': [{'datapoint_value': 'greenhouses'}],\n",
      "           '_id': 'b3ce19ed-9baa-4ea3-8f05-555ab64f0fd4',\n",
      "           '_score': 0.7853126840150648,\n",
      "           'company_id': '123',\n",
      "           'company_name': 'Rough Brothers Holding Co., Inc',\n",
      "           'datapoint_type': 'product',\n",
      "           'datapoint_value': 'greenhouses',\n",
      "           'source_excerpts': ['Rough (rhymes with now) doesnt just design and '\n",
      "                               'build greenhouses (commercial, retail and '\n",
      "                               'institutional)...',\n",
      "                               'St. Bernard-based Rough Brothers was founded '\n",
      "                               'in 1932 and is among North Americas largest '\n",
      "                               'greenhouse manufacturers.'],\n",
      "           'source_inferred': ['null', 'null'],\n",
      "           'source_urls': ['https://www.growertalks.com/Article/?articleid=21683',\n",
      "                           'https://www.cincinnati.com/story/money/2015/07/08/rough-brothers-rbi-sold/29870299/']},\n",
      "          {'_highlights': [{'company_name': 'Rough Brothers Holding Co., Inc'}],\n",
      "           '_id': '7cfb0edc-d930-4335-a7ba-5bc0e9eb08cf',\n",
      "           '_score': 0.7833975829061365,\n",
      "           'company_id': '123',\n",
      "           'company_name': 'Rough Brothers Holding Co., Inc',\n",
      "           'datapoint_type': 'product',\n",
      "           'datapoint_value': 'solar panel racking systems',\n",
      "           'source_excerpts': ['they also have a division that designs and '\n",
      "                               'installs racks for solar panels.'],\n",
      "           'source_inferred': ['Solar panel racking systems are part of '\n",
      "                               \"Rough's offerings as they have a division that \"\n",
      "                               'designs and installs racks for solar panels.'],\n",
      "           'source_urls': ['https://www.growertalks.com/Article/?articleid=21683']},\n",
      "          {'_highlights': [{'company_name': 'Rough Brothers Holding Co., Inc'}],\n",
      "           '_id': '8361b4e3-6cad-4138-a52f-fd46f9249e60',\n",
      "           '_score': 0.7833975829061365,\n",
      "           'company_id': '123',\n",
      "           'company_name': 'Rough Brothers Holding Co., Inc',\n",
      "           'datapoint_type': 'product',\n",
      "           'datapoint_value': 'solar panel racking systems',\n",
      "           'source_excerpts': ['they also have a division that designs and '\n",
      "                               'installs racks for solar panels.'],\n",
      "           'source_inferred': ['Solar panel racking systems are part of '\n",
      "                               \"Rough's offerings as they have a division that \"\n",
      "                               'designs and installs racks for solar panels.'],\n",
      "           'source_urls': ['https://www.growertalks.com/Article/?articleid=21683']},\n",
      "          {'_highlights': [{'datapoint_value': 'Laser cutting and welding '\n",
      "                                               'equipment'}],\n",
      "           '_id': '3d54845e-984c-4a60-98e2-4e6fe399087a',\n",
      "           '_score': 0.7828792572332105,\n",
      "           'company_id': '456',\n",
      "           'company_name': 'Greatbatch Ltd.',\n",
      "           'datapoint_type': 'product',\n",
      "           'datapoint_value': 'Laser cutting and welding equipment',\n",
      "           'source_excerpts': ['they also have a division that designs and '\n",
      "                               'installs racks for solar panels.'],\n",
      "           'source_inferred': ['Solar panel racking systems are part of '\n",
      "                               \"Rough's offerings as they have a division that \"\n",
      "                               'designs and installs racks for solar panels.'],\n",
      "           'source_urls': ['https://www.growertalks.com/Article/?articleid=21683']}],\n",
      " 'limit': 10,\n",
      " 'offset': 0,\n",
      " 'processingTimeMs': 137,\n",
      " 'query': 'What companies are located in Buffalo that service gas pipes and '\n",
      "          'lines?'}\n"
     ]
    }
   ],
   "source": [
    "query=\"What companies are located in Buffalo that service gas pipes and lines?\"\n",
    "print(f\"\\nThe query was: {query}\")\n",
    "\n",
    "# Vector Search Results\n",
    "print(\"\\nHits from Vector DB: \\n==============\\n\")\n",
    "results = mq.index(index_name).search(q=query)\n",
    "print(f\"ID: {results['hits'][0]['_id']}, Score: {results['hits'][0]['_score']:.3f}.\")\n",
    "print(\"Company Name:\", results['hits'][0]['company_name'])\n",
    "print(\"Relevant data:\")\n",
    "pprint(results['hits'][0]['_highlights'])\n",
    "pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hits from LLama 3.1-8B Model: \n",
      "==============\n",
      "\n",
      "\n",
      "Here is some information about various companies:\n",
      "company_name: Pii Holdings, Inc.\n",
      "datapoint_type: product\n",
      "datapoint_value: gas pipe fixtures\n",
      "source_excerpts: we do gas pipes on a daily basis.\n",
      "company_name: XYZ Inc.\n",
      "datapoint_type: location\n",
      "datapoint_value: 3288 Main St. Buffalo NY\n",
      "source_excerpts: visit our website.\n",
      "company_name: Pii Holdings, Inc.\n",
      "datapoint_type: location\n",
      "datapoint_value: 2150 Elmwood Avenue Buffalo, NY\n",
      "source_excerpts: they also have a division that designs and installs racks for solar panels.\n",
      "company_name: Pii Holdings, Inc.\n",
      "datapoint_type: location\n",
      "datapoint_value: 2150 Elmwood Avenue Buffalo, NY\n",
      "source_excerpts: they also have a division that designs and installs racks for solar panels.\n",
      "company_name: XYZ Inc.\n",
      "datapoint_type: product\n",
      "datapoint_value: 3D printing\n",
      "source_excerpts: our latest resin printers and sintering machines.\n",
      "company_name: Rough Brothers Holding Co., Inc\n",
      "datapoint_type: product\n",
      "datapoint_value: greenhouses\n",
      "source_excerpts: Rough (rhymes with now) doesnt just design and build greenhouses (commercial, retail and institutional)..., St. Bernard-based Rough Brothers was founded in 1932 and is among North Americas largest greenhouse manufacturers.\n",
      "company_name: Rough Brothers Holding Co., Inc\n",
      "datapoint_type: product\n",
      "datapoint_value: greenhouses\n",
      "source_excerpts: Rough (rhymes with now) doesnt just design and build greenhouses (commercial, retail and institutional)..., St. Bernard-based Rough Brothers was founded in 1932 and is among North Americas largest greenhouse manufacturers.\n",
      "company_name: Rough Brothers Holding Co., Inc\n",
      "datapoint_type: product\n",
      "datapoint_value: solar panel racking systems\n",
      "source_excerpts: they also have a division that designs and installs racks for solar panels.\n",
      "company_name: Rough Brothers Holding Co., Inc\n",
      "datapoint_type: product\n",
      "datapoint_value: solar panel racking systems\n",
      "source_excerpts: they also have a division that designs and installs racks for solar panels.\n",
      "company_name: Greatbatch Ltd.\n",
      "datapoint_type: product\n",
      "datapoint_value: Laser cutting and welding equipment\n",
      "source_excerpts: they also have a division that designs and installs racks for solar panels.\n",
      "\n",
      "Use this information to answer questions.\n",
      "Do NOT make up an answer if you do not know.\n",
      "Your brief, short response should not be more than two sentences long.\n",
      "Do not write code - return a plaintext answer to the following question:\n",
      "Q: What companies are located in Buffalo that service gas pipes and lines?\n",
      "A:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 550 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =   12604.88 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   473 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   42167.26 ms /   474 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pii Holdings, Inc\n",
      " is located in Buffalo and services gas pipes and lines\n",
      "  Pii Holdings, Inc\n"
     ]
    }
   ],
   "source": [
    "# Create Context for Prompt\n",
    "likely_results = []\n",
    "prompt_context_string=\"\"\n",
    "ignored_fields = [\"_highlights\",\"_id\", \"company_id\",\"_score\",\"source_urls\",\"source_inferred\"]\n",
    "for result in results['hits']:\n",
    "    for field in ignored_fields:\n",
    "        if field in result:\n",
    "            result.pop(field)\n",
    "    for key, value in flatten_json(result).items():\n",
    "        prompt_context_string += f\"{key}: {value}\\n\"\n",
    "    #prompt_context_string += '\\n'\n",
    "\n",
    "# Using LLama with context\n",
    "print(\"\\nHits from LLama 3.1-8B Model: \\n==============\\n\")\n",
    "prompt = f\"\"\"\n",
    "Here is some information about various companies:\n",
    "{prompt_context_string}\n",
    "Use this information to answer questions.\n",
    "Do NOT make up an answer if you do not know.\n",
    "Your brief, short response should not be more than two sentences long.\n",
    "Do not write code - return a plaintext answer to the following question:\n",
    "Q: {query}\n",
    "A:\"\"\"\n",
    "print(prompt)\n",
    "\n",
    "model_output = LLM(\n",
    "    prompt, \n",
    "    max_tokens=512, \n",
    "    stop=[\"Q:\"],\n",
    "    top_p=0.1,\n",
    "    temperature=0.1\n",
    ")[\"choices\"][0][\"text\"]\n",
    "\n",
    "for sentence in model_output.split('.')[:3]:\n",
    "    print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
